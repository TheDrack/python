# M√≥dulo de Reinforcement Learning (RL-Evolution) ü§ñ

## Vis√£o Geral

O m√≥dulo RL-Evolution implementa um sistema de Aprendizado por Refor√ßo para o JARVIS, permitindo que o assistente aprenda com suas a√ß√µes passadas e melhore continuamente sua efici√™ncia.

## Funcionalidades

### 1. Sistema de Recompensas (Reward System)

- **Tabela de Banco de Dados**: `evolution_rewards` no Supabase/PostgreSQL
- **Tipos de A√ß√µes Rastreadas**:
  - ‚úÖ `pytest_pass`: Testes passaram (+10 pontos base)
  - ‚ùå `pytest_fail`: Testes falharam (-5 pontos base)
  - ‚úÖ `deploy_success`: Deploy bem-sucedido (+50 pontos)
  - ‚ùå `deploy_fail`: Deploy falhou (-25 pontos)
  - üîÑ `rollback`: Rollback necess√°rio (-30 pontos)
  - üìà `roadmap_progress`: Progresso no roadmap (+20 pontos por %)
  - üéØ `capability_complete`: Capacidade completa (+15 pontos)
  - ‚ö° `capability_partial`: Capacidade parcial (+5 pontos)

### 2. L√≥gica de Rotina (Routine Logic)

O servi√ßo `EvolutionLoopService` pode ser executado:

- Ap√≥s cada execu√ß√£o de testes (pytest)
- Ap√≥s cada deployment (sucesso ou falha)
- Quando o progresso do roadmap aumenta
- Em intervalos de tempo definidos
- No login do HUD

### 3. Feedback Loop

O sistema cria um ciclo de feedback:

1. **A√ß√£o**: Pytest, deploy, ou atualiza√ß√£o de capacidade
2. **Recompensa**: Pontos positivos ou negativos s√£o atribu√≠dos
3. **An√°lise**: M√©tricas de efici√™ncia s√£o calculadas
4. **Melhoria**: Recomenda√ß√µes s√£o geradas para futuras a√ß√µes

### 4. Policy Engine (Motor de Pol√≠ticas)

Usa o **Llama 3.3-70b (High Gear)** para analisar o hist√≥rico de recompensas e:

- Identificar padr√µes de erro
- Recomendar o caminho mais seguro para a pr√≥xima meta
- Sugerir melhorias para aumentar a efici√™ncia
- Aprender com erros passados

### 5. Status de Efici√™ncia

Exibe no login do HUD:

```
üìà Comandante, meu n√≠vel de efici√™ncia aumentou 72.5 pontos baseado nas √∫ltimas evolu√ß√µes (Taxa de sucesso: 57.1%)
```

## Arquitetura

O m√≥dulo segue a **Arquitetura Hexagonal** (Clean Architecture):

```
Domain Layer (app/domain/models/)
‚îú‚îÄ‚îÄ evolution_reward.py         # Modelo de dados SQLModel

Application Layer
‚îú‚îÄ‚îÄ ports/
‚îÇ   ‚îî‚îÄ‚îÄ reward_provider.py      # Interface (porta)
‚îî‚îÄ‚îÄ services/
    ‚îî‚îÄ‚îÄ evolution_loop.py       # L√≥gica de neg√≥cio

Infrastructure Layer (app/adapters/)
‚îî‚îÄ‚îÄ infrastructure/
    ‚îî‚îÄ‚îÄ reward_adapter.py       # Implementa√ß√£o do banco de dados
```

## Instala√ß√£o

### 1. Migra√ß√£o do Banco de Dados

Execute a migra√ß√£o SQL no Supabase:

```sql
-- Arquivo: migrations/002_create_evolution_rewards.sql
-- Cria a tabela evolution_rewards
```

Para aplicar manualmente:

```bash
psql -h db.saibtpdehhprttqlgqdt.supabase.co -U postgres -d postgres -f migrations/002_create_evolution_rewards.sql
```

### 2. Depend√™ncias

Todas as depend√™ncias j√° est√£o inclu√≠das em `requirements.txt`:

- SQLModel (ORM)
- SQLAlchemy
- Groq (para Llama 3.3-70b)

## Uso

### 1. Exemplo B√°sico - Logging de Pytest

```python
from app.adapters.infrastructure.sqlite_history_adapter import SQLiteHistoryAdapter
from app.adapters.infrastructure.reward_adapter import RewardAdapter
from app.application.services.evolution_loop import EvolutionLoopService
from app.core.config import settings

# Inicializar servi√ßos
db_adapter = SQLiteHistoryAdapter(database_url=settings.database_url)
reward_adapter = RewardAdapter(engine=db_adapter.engine)
evolution_service = EvolutionLoopService(reward_provider=reward_adapter)

# Logar resultado de teste
evolution_service.log_pytest_result(
    passed=True,
    test_count=25,
    metadata={'ci_run_id': 'abc123', 'branch': 'main'}
)
```

### 2. Exemplo - Logging de Deploy

```python
# Deploy bem-sucedido
evolution_service.log_deploy_result(
    success=True,
    deployment_id='deploy-123',
    metadata={'environment': 'production'}
)

# Deploy com falha
evolution_service.log_deploy_result(
    success=False,
    error_message='Build failed',
    metadata={'environment': 'staging'}
)

# Rollback
evolution_service.log_deploy_result(
    success=False,
    rollback=True,
    error_message='Critical bug detected'
)
```

### 3. Exemplo - Status de Efici√™ncia

```python
# Obter status para exibir no HUD
status = evolution_service.get_evolution_status(days=7)

print(status['commander_message'])
# üìà Comandante, meu n√≠vel de efici√™ncia aumentou 72.5 pontos...

print(f"Efficiency Score: {status['efficiency_score']}")
print(f"Success Rate: {status['success_rate']}%")
```

### 4. Exemplo - Policy Engine (An√°lise com IA)

```python
# Requer AIGateway configurado
from app.adapters.infrastructure.ai_gateway import AIGateway

ai_gateway = AIGateway(groq_api_key="...", groq_model="llama-3.3-70b-versatile")
evolution_service = EvolutionLoopService(
    reward_provider=reward_adapter,
    ai_gateway=ai_gateway
)

# An√°lise ass√≠ncrona
analysis = await evolution_service.analyze_with_policy_engine(days=30)
print(analysis['analysis'])
# IA retorna recomenda√ß√µes baseadas em erros passados
```

## Scripts CLI

### 1. Visualizar Status de RL

```bash
python scripts/show_rl_status.py --days 7
```

Exibe:
- Mensagem do comandante
- M√©tricas de efici√™ncia
- Breakdown por tipo de a√ß√£o
- √öltimos 10 eventos

### 2. Exemplo de Integra√ß√£o

```bash
python scripts/example_evolution_integration.py
```

Demonstra todos os cen√°rios de uso:
- Integra√ß√£o com pytest
- Integra√ß√£o com deploys
- Progresso de roadmap
- Status no HUD
- Policy Engine

## Integra√ß√£o com CI/CD

### GitHub Actions

```yaml
# .github/workflows/test.yml
- name: Run Tests
  id: test
  run: pytest
  continue-on-error: true

- name: Log Test Results to RL
  run: |
    python -c "
    from app.application.services.evolution_loop import EvolutionLoopService
    from app.adapters.infrastructure.reward_adapter import RewardAdapter
    from app.adapters.infrastructure.sqlite_history_adapter import SQLiteHistoryAdapter
    from app.core.config import settings
    
    db = SQLiteHistoryAdapter(database_url=settings.database_url)
    reward = RewardAdapter(engine=db.engine)
    evolution = EvolutionLoopService(reward_provider=reward)
    
    passed = '${{ steps.test.outcome }}' == 'success'
    evolution.log_pytest_result(passed=passed, metadata={'workflow': 'CI'})
    "
```

### Deploy com Render

```yaml
# render.yaml
services:
  - type: web
    name: jarvis
    env: python
    buildCommand: |
      pip install -r requirements.txt
      python -c "
      from app.application.services.evolution_loop import EvolutionLoopService
      # Log deploy success
      "
```

## Integra√ß√£o com Container DI

O m√≥dulo est√° integrado ao container de inje√ß√£o de depend√™ncias:

```python
from app.container import Container

container = Container()

# Acessar servi√ßo de evolu√ß√£o
evolution_service = container.evolution_loop_service

# Logar a√ß√µes
evolution_service.log_pytest_result(passed=True, test_count=10)
```

## M√©tricas e Estat√≠sticas

### Efficiency Score

Soma total de todos os pontos de recompensa:

- Positivo: Sistema est√° melhorando
- Negativo: Sistema precisa de ajustes
- Zero: Sistema est√°vel

### Success Rate

Percentual de a√ß√µes bem-sucedidas vs total:

- ‚â• 70%: üü¢ Excelente
- 50-70%: üü° Bom
- < 50%: üî¥ Necessita melhoria

### Improvement

Compara√ß√£o entre per√≠odo atual e anterior:

- Positivo: Efici√™ncia aumentou
- Negativo: Efici√™ncia diminuiu
- Zero: Manteve-se est√°vel

## Estrutura do Banco de Dados

```sql
CREATE TABLE evolution_rewards (
    id SERIAL PRIMARY KEY,
    action_type VARCHAR(100) NOT NULL,      -- Tipo de a√ß√£o
    reward_value FLOAT NOT NULL,            -- Pontos (+/-)
    context_data JSONB DEFAULT '{}',        -- Contexto da a√ß√£o
    meta_data JSONB DEFAULT '{}',           -- Metadados adicionais
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

**Exemplo de registro**:

```json
{
  "id": 1,
  "action_type": "pytest_pass",
  "reward_value": 25.0,
  "context_data": {
    "passed": true,
    "test_count": 10,
    "failed_tests": []
  },
  "meta_data": {
    "ci_run_id": "abc123",
    "branch": "main"
  },
  "created_at": "2026-02-11T01:12:04Z"
}
```

## Testes

Execute os testes do m√≥dulo:

```bash
pytest tests/test_evolution_loop.py -v
```

**Cobertura**: 82% do evolution_loop.py (24 testes passando)

## Roadmap Futuro

- [ ] Dashboard web interativo para visualiza√ß√£o
- [ ] Alertas autom√°ticos quando efici√™ncia cai
- [ ] Integra√ß√£o com Slack/Discord para notifica√ß√µes
- [ ] An√°lise preditiva de falhas
- [ ] Recomenda√ß√µes autom√°ticas de PRs
- [ ] A/B testing de diferentes estrat√©gias

## Contribuindo

1. Novos tipos de a√ß√£o devem ser adicionados em `EvolutionLoopService.REWARDS`
2. Testes devem ser criados em `tests/test_evolution_loop.py`
3. Documenta√ß√£o deve ser atualizada neste README

## Suporte

Para d√∫vidas ou problemas:

1. Verifique os logs: `evolution_service` usa logging Python
2. Execute `show_rl_status.py` para verificar o estado
3. Consulte os exemplos em `scripts/example_evolution_integration.py`

## Licen√ßa

Mesma licen√ßa do projeto principal JARVIS.
